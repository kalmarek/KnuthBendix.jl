var documenterSearchIndex = {"docs":
[{"location":"words/#Words","page":"Words","title":"Words","text":"","category":"section"},{"location":"words/","page":"Words","title":"Words","text":"CurrentModule=KnuthBendix","category":"page"},{"location":"words/#AbstractWord-interface","page":"Words","title":"AbstractWord interface","text":"","category":"section"},{"location":"words/","page":"Words","title":"Words","text":"Words.AbstractWord","category":"page"},{"location":"words/#KnuthBendix.Words.AbstractWord","page":"Words","title":"KnuthBendix.Words.AbstractWord","text":"AbstractWord{T} <: AbstractVector{T}\n\nAbstract type representing words over an Alphabet.\n\nAbstractWord is just a string of integers and as such gains its meaning in the contex of an Alphabet (when integers are understood as pointers to letters). The subtypes of AbstractWord{T} need to implement the following methods which constitute AbstractWord interface:\n\na constructor from AbstractVector{T} with check optional argument (true implies checking the validity of input),\nlinear indexing (1-based) consistent with iteration returning pointers to letters of an alphabet (getindex, setindex, size).\n\nnote: Note\nIt is assumed that eachindex(w::AbstractWord) returns Base.OneTo(length(w))\nthe lenght(w) must represented the length of the word as it is written in an alphabet, and neither its shortest form (e.g. the normal form) nor the length of the freely reduced form.\n\nBase.push!/Base.pushfirst!: append a single value at the end/beginning,\nBase.pop!/Base.popfirst!: pop a single value from the end/beginning,\nBase.append!/Base.prepend!: append a another word at the end/beginning,\nBase.resize!: drop/extend a word at the end to the requested length\nBase.similar: an uninitialized word of a similar type/storage.\n\nThe following are implemented for AbstractWords but can be overloaded for performance reasons:\n\nBase.==: the equality (as words),\nBase.hash: simple uniqueness hashing function\nBase.view: creating SubWord e.g. based on subarray.\n\n\n\n\n\n","category":"type"},{"location":"words/#Auxillary-functions","page":"Words","title":"Auxillary functions","text":"","category":"section"},{"location":"words/","page":"Words","title":"Words","text":"Words.longestcommonprefix\nWords.lcp\nWords.isprefix\nWords.issuffix","category":"page"},{"location":"words/#KnuthBendix.Words.longestcommonprefix","page":"Words","title":"KnuthBendix.Words.longestcommonprefix","text":"longestcommonprefix(u::AbstractWord, v::AbstractWord)\n\nReturns the length of longest common prefix of two words (and simultaneously the index at which the prefix ends).\n\n\n\n\n\n","category":"function"},{"location":"words/#KnuthBendix.Words.lcp","page":"Words","title":"KnuthBendix.Words.lcp","text":"lcp(u::AbstractWord, v::AbstractWord)\n\nSee longestcommonprefix.\n\n\n\n\n\n","category":"function"},{"location":"words/#KnuthBendix.Words.isprefix","page":"Words","title":"KnuthBendix.Words.isprefix","text":"isprefix(u::AbstractWord, v::AbstractWord)\n\nCheck if u is a prefix of v.\n\n\n\n\n\n","category":"function"},{"location":"words/#KnuthBendix.Words.issuffix","page":"Words","title":"KnuthBendix.Words.issuffix","text":"issuffix(u::AbstractWord, v::AbstractWord)\n\nCheck if u is a suffix of v.\n\n\n\n\n\n","category":"function"},{"location":"words/#Implementations","page":"Words","title":"Implementations","text":"","category":"section"},{"location":"words/","page":"Words","title":"Words","text":"Words.Word\nWords.SubWord\nWords.BufferWord","category":"page"},{"location":"words/#KnuthBendix.Words.Word","page":"Words","title":"KnuthBendix.Words.Word","text":"Word{T} <: AbstractWord{T}\n\nWord as written in an alphabet storing only letters indices in an Alphabet.\n\nThe letters are stored in a plain Vector{T} field.\n\nIf type is not specified in the constructor it will default to UInt16.\n\n\n\n\n\n","category":"type"},{"location":"words/#KnuthBendix.Words.SubWord","page":"Words","title":"KnuthBendix.Words.SubWord","text":"SubWord{...}\n\nA non-copying view into an existing word.\n\nSubWords are note intended to be constructed by other means than view function or the @view macro.\n\njulia> w = Word(1:5)\nWord{UInt16}: 1·2·3·4·5\n\njulia> v = @view w[3:5]\nSubWord{UInt16, …}: 3·4·5\n\njulia> length(v)\n3\n\n\n\n\n\n\n","category":"type"},{"location":"words/#KnuthBendix.Words.BufferWord","page":"Words","title":"KnuthBendix.Words.BufferWord","text":"BufferWord{T} <: AbstractWord{T}\nBufferWord{T}([content::AbstractVector],\n    free_before::Integer = 8,\n    free_after::Integer = 8,\n    [check = true])\n\nA word type with constant complexity push! and popfirst! operations. Ideal for Rewriting(@ref).\n\nThe letters are stored in a plain Vector{T} field. In contrast to Word(@ref) the push! pop!, pushfirst!, popfirst! etc. operations are (amortized) O(1) complexity. BufferWord achieves this by storing pointers to the beginning and the end of the valid part of the storage and consistent indexing.\n\nIf type is not specified in the constructor it will default to UInt16.\n\n\n\n\n\n","category":"type"},{"location":"knuthbendix_completion/#Confluence-and-the-Knuth-Bendix-completion","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"","category":"section"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"Confluence is a notion that describes in a formal way the independence of the result of the rewriting procedure (w.r.t. mathcalR) on particular choices made in the process (without specifying any algorithm!). In colloquial form it goes like this: whenever the rewrite paths of any word w diverge, there is a common point later where they agree again. In more formal way","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"info: Confluence\nWe say that a rewriting system mathcalR is confulent if for every word w in mathcalA^* and two rewrites p_1 p_2 in mathcalA^* of w there exist a common rewrite q in mathcalA^* for both of them.","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"Let us denote by w xrightarrow_mathcalR p that p is the result of applying a single rewriting rule from mathcalR once to w, and by w xrightarrow*_mathcalR p that p is the result of rewriting of w with any number of rules from mathcalR. Confluence can be succintly phrased as","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"forallw left(\n(p_1 _mathcalRxleftarrow* w xrightarrow*_mathcalR p_2)\nimplies exists q \np_1 xrightarrow*_mathcalR q _mathcalRxleftarrow* p_2right)","category":"page"},{"location":"knuthbendix_completion/#Local-confluence-and-suffix-prefix-words","page":"Confluence and the Knuth-Bendix completion","title":"Local confluence and suffix-prefix words","text":"","category":"section"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"It turns out that confluence is equivalent to local confluence. What does local mean? That we allow only a single rewrite by a rule of mathcalR to arrive at p_1 or p_2 (q can be still arrived at by arbitrary number of rewrties):","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"forallw left(\n(p_1 _mathcalRxleftarrow w xrightarrow_mathcalR p_2)\nimplies exists q \np_1 xrightarrow*_mathcalR q _mathcalRxleftarrow* p_2right)","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"Local confluence seems a much weaker condition than normal confluence and yet they are equivalent and the former is much easier to check! While the set of words for which local confluence fails may be infinite, the shortest among them, i.e. the ones where local confluence holds for all proper subwords, can be characterized in terms of mathcalR explicitly! They are formed from pairs of rules where a suffix of the left-hand-side of one rule is a prefix of the left-hand-side of the other. Suppose we have two rules p_i to q_i (i = 12) and that p_1 = acdot b and p_2 = bcdot c (b neq varepsilon), we can rewrite w = acdot b cdot c","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"q_1 cdot c _mathcalRxleftarrow\np_1 cdot c = w = acdot p_2\nxrightarrow_mathcalR Acdot q_2","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"in two (potentially) different ways. If we can show that none of the candidates fails local confluence the rewriting system mathcalR is confluent and hence can be used to solve the word problem!","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"Note, however, that as we check a pair of rules for failure to local confluence, new rewriting rules are often discovered and added to mathcalR hence new additional pairs of rules need to be checked and the whole process becomes potentially infinite.","category":"page"},{"location":"knuthbendix_completion/#Knuth-Bendix-completion-an-example","page":"Confluence and the Knuth-Bendix completion","title":"Knuth Bendix completion - an example","text":"","category":"section"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"Let us work out an example. We begin with alphabet mathcalA = a A b ordered by the length-then-lexicographical order on mathcalA^* defined by a  A  b.","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"Here are our generating pairs for the congruence:","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"R = (aA varepsilon) (Aa varepsilon) (bbb varepsilon) (ab ba)","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"We note that in the last pair we have ab  ba, so we will need to reverse the pair while the initial rewriting system mathcalR. It consists of the following rules:","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"aA to varepsilon,\nAa to varepsilon,\nbbb to varepsilon,\nba to ab.\nIs this system confluent? As one indication of non-confluence we could observe that while b commutes with a, we have no idea so far if b commutes with A. Well we know that it should, since A smells like an \"inverse\" of a but the rewriting system doesn't know this yet! Let us proceed through the Knuth-Bendix procedure of discovering new rules through suffix-prefix 'intersections' of rules left-hand-sides.\nAnalyzing pair (1,1) gives no suffix-prefix word, hence no candidates for failure of local confluence.\nAnalyzing rule (1,2) we see that with suffix-prefix equal to A we can rewrite acdot Acdot a by either rule 1 or rule 2 (we used cdot to separate the suffix-prefix word). Both rewrites result in varepsilon cdot a = a = a cdotvarepsilon, so the local confluence holds here (and similarly for (2,1)).\nPair (2,2) gives no candidates and so do pairs (3,1) and (3,2).\nPair (3,3) results in candidates bbcdot b cdot bb and bcdot bbcdot b. Both of rewrites of these words lead to the same result (either bb, or b), so local confluence still holds here.\nNo further candidates are uncoverd considering pairs (3, 1) and (3, 2).\nFinally moving to rule 4 we see something interesting:\npairs (1,4) and (2,4) give no candidates;\npair (3,4) results in word bbcdot bcdot a which can be rewritten in two essentially different ways: p_1 = varepsilon cdot a = a, or p_2 = bbcdot ab. However applying rule 4 two more times rewrites the latter to p_2 = acdot bbb and after the final rewrite with rule 3 we obtain q = acdot varepsilon = a. Thus p_2 xrightarrow*_mathcalR q = p_1 and local confluence holds here  as well.\npair (4,4) gives no candidates\npair (4,1) results in word bcdot acdot A with two essentially different rewrites: p_1 = abcdot A and p_2 = b cdot varepsilon = b. None of p_1 and p_2 can be rewritten any further, so we found the first failure to the local confluence and in the process we discovered a new rewriting rule which we add to mathcalR (after the appropriate reordering) as\nabA to b.\nFurther pairs (4,2) and (4,3) give no candidates for local confluence. However, we are not finished yet, since we've added rule 5 and we have 9 more pairs of rules to check. For brevity let's discuss onlt those pairs which give candidates:\n(5,2): the candidate word ab cdot A cdot a rewrites as either ab or aAba; applying rules 1 and 4 to the latter we arrive at ab and no failure to local confluence is discovered.\n(2,5): the candidate word Acdot acdot bA rewrites as bA (rule 2) or as Ab (rule 5), which leads to new rule\nbA to Ab\n(4,5): the candidate word bcdot a cdot bA rewrites as bb (rule 5) or as abbA (rule 4) which rewrites further to bb (twice applying newly discovered rule 6 then rule 1). Local confluence holds for this pair.\nAt this point we have finished processing rule 5, but now we have 11 more pairs to check with our newly added rule 6. Processing those we arrive at three candidates (from pairs (3,6), (5,6), and (6,2)). None of these fails local confluence, hence we stop and report the rewriting system with rules 1-6 as confluent.","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"warning: Warning\nNote that had we chosen a different order of processing the pairs we could have ended with an infinite sequence of rules of the form a^n b A^n to b and the process might have never stopped. This order in particular is dependent on the ordering of mathcalA^* as we have essentially reduced the word problem to the problem of finding an order on which Knuth-Bendix completion terminates.","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"One may observe that once we discver rule 6, rule 5 becomes redundant: we can apply rule 6 to the left-hand-side of rule 5 which leads to abA xrightarrow aAb xrightarrow b, i.e. rule 5 is a consequence of rules 1 and 6, and as such can be removed. The minimal set of rules forms the (unique!) reduced confluent rewriting system mathcalRC(R ), which in this case consists of","category":"page"},{"location":"knuthbendix_completion/","page":"Confluence and the Knuth-Bendix completion","title":"Confluence and the Knuth-Bendix completion","text":"aA to varepsilon,\nAa to varepsilon,\nbbb to varepsilon,\nba to ab,\nbA to Ab.","category":"page"},{"location":"parsing_kbmag/","page":"Parsing kbmag input files","title":"Parsing kbmag input files","text":"CurrentModule = KnuthBendix\nDocTestSetup  = quote\n    using KnuthBendix\nend","category":"page"},{"location":"parsing_kbmag/","page":"Parsing kbmag input files","title":"Parsing kbmag input files","text":"KnuthBendix.jl provides a very simple parsing of the kbmag input files. To replicate e.g. Example 1 from GAP documentation you can run","category":"page"},{"location":"parsing_kbmag/","page":"Parsing kbmag input files","title":"Parsing kbmag input files","text":"julia> example1_str = \"\"\"rec(\n              isRWS := true,\n         generatorOrder := [_g1,_g2,_g3],\n           inverses := [_g1,_g3,_g2],\n           ordering := \"shortlex\",\n          equations := [\n            [_g2^2,_g3],\n            [_g1*_g2*_g1,_g3*_g1*_g3]\n          ]\n       )\"\"\";\n\njulia> kbrws = KnuthBendix.parse_kbmag(example1_str)\nrec(\n           isRWS := true,\n  generatorOrder := [_g1,_g2,_g3],\n        inverses := [_g1,_g3,_g2],\n        ordering := \"shortlex\",\n       equations := [\n    [_g2*_g2, _g3],\n    [_g1*_g2*_g1, _g3*_g1*_g3]\n  ]\n)\n\njulia> rws = RewritingSystem(kbrws)\nRewriting System with 5 active rules ordered by LenLex: _g1 < _g2 < _g3:\n┌──────┬──────────────────────────────────┬──────────────────────────────────┐\n│ Rule │                              lhs │ rhs                              │\n├──────┼──────────────────────────────────┼──────────────────────────────────┤\n│    1 │                            _g1^2 │ (id)                             │\n│    2 │                          _g2*_g3 │ (id)                             │\n│    3 │                          _g3*_g2 │ (id)                             │\n│    4 │                            _g2^2 │ _g3                              │\n│    5 │                      _g3*_g1*_g3 │ _g1*_g2*_g1                      │\n└──────┴──────────────────────────────────┴──────────────────────────────────┘\n\n\njulia> knuthbendix(rws)\nRewriting System with 11 active rules ordered by LenLex: _g1 < _g2 < _g3:\n┌──────┬──────────────────────────────────┬──────────────────────────────────┐\n│ Rule │                              lhs │ rhs                              │\n├──────┼──────────────────────────────────┼──────────────────────────────────┤\n│    1 │                            _g1^2 │ (id)                             │\n│    2 │                          _g2*_g3 │ (id)                             │\n│    3 │                          _g3*_g2 │ (id)                             │\n│    4 │                            _g2^2 │ _g3                              │\n│    5 │                      _g3*_g1*_g3 │ _g1*_g2*_g1                      │\n│    6 │                            _g3^2 │ _g2                              │\n│    7 │                  _g1*_g2*_g1*_g3 │ _g3*_g1*_g2                      │\n│    8 │                  _g3*_g1*_g2*_g1 │ _g2*_g1*_g3                      │\n│    9 │                      _g2*_g1*_g2 │ _g1*_g3*_g1                      │\n│   10 │                  _g2*_g1*_g3*_g1 │ _g3*_g1*_g2                      │\n│   11 │                  _g1*_g3*_g1*_g2 │ _g2*_g1*_g3                      │\n└──────┴──────────────────────────────────┴──────────────────────────────────┘\n\n","category":"page"},{"location":"knuthbendix_idxA/#Using-index-automaton","page":"Using index automaton","title":"Using index automaton","text":"","category":"section"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"Now we will obtain major speedups in rewriting by using a special data structure to keep our rewriting system. The structure is known as an index automaton in this context[Sims1994], but a more widely name for the automaton is the Aho-Corasik automaton[Aho1975]. This automaton provides an optimal complexity for string searching in a corpus, namely, once the automaton is built, the rewriting takes Ω(m) where m is the length of the word to be rewritten. Thus we can obtain rewrites independent of the size of the rewriting system.","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"This version of Knuth-Bendix completion is uses Index automaton rewriting for fast rewrites.","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"Keeping the construction of the automaton as a black box, below is a julia-flavoured pseudocode describing the completion procedure.","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"function knuthbendix2automaton(rws::RewritingSystem{W}, MAX_STACK, ...) where W\n    stack = Vector{Tuple{W,W}}()\n    rws = reduce(rws)  # this is assumed by IndexAutomaton!\n    idxA = Automata.IndexAutomaton(rws)\n\n    # ... initialize more temporary structures here\n    for ri in rules(rws)\n        for rj in rules(rws)\n            isactive(ri) || break\n            find_critical_pairs!(stack, idxA, ri, rj, ...)\n            ri === rj && break\n            isactive(ri) || break\n            isactive(rj) || continue\n            find_critical_pairs!(stack, idxA, rj, ri, ...)\n        end\n        if lenght(stack) > MAX_STACK || ri == last(rules(rws))\n            rws, idxA, ... = Automata.rebuild!(idxA, rws, stack, ...)\n            # rebuild! reduces rws and rebuilds idxA on top\n        end\n        ...\n    end\n    return rws\nend","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"CurrentModule = KnuthBendix","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"The main difference in the procedure is that instead immediately forcing reducedness with every discovered rule we delay this check until stack is bigger than a user provided MAX_STACK. Only then is the Automata.rebuild! invoked which","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"uses deriverule! to push  all critical pairs from stack to rws while maintaining its reducedness,\nremoves inactive rules from rws,\nrebuilds idxA the index automaton for rws.","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"This allows to amortize the time needed for reduction of rws (dominating!) and the construction of idxA (rather cheap, in comparison) across many different pairs of rules (ri, rj).","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"knuthbendix!(::KBS2AlgIndexAut, args...)\nAutomata.rebuild!","category":"page"},{"location":"knuthbendix_idxA/#On-index-automaton","page":"Using index automaton","title":"On index automaton","text":"","category":"section"},{"location":"knuthbendix_idxA/#Backtrack-search-and-test-for-confluence","page":"Using index automaton","title":"Backtrack search and test for confluence","text":"","category":"section"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"Another very important feature of IndexAutomaton is that it allows us to test cheaply for confluence. Normally we need to check all pairs of rules for their suffix-prefix intersections and resolve the potentially critical pairs. However if we have an idxA::IndexAutomaton at hand checking for confluence becomes much easier: given a rule lhs → rhs from our rewriting system we need to see how can we extend lhs[2:end] to a word w which ends with the left-hand-side lhs' of some other rule. We need to be careful though that the length of w is not too large (otherwise w = lhs[2:end]*X*lhs' and we don't get our candidate for the failure of local confluence). If you think about index automaton as a tree with some (plenty of) additional edges, then the answer is right there: for every lhs we need to perform a single backtrack search on idxA. Where do we start? At the last state of trace(idxA, lhs[2:end]). When do we backtrack?","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"when the depth of search becomes too large i.e. equal to lenght(lhs[2:end]), or\nwhen the edge lead us to a vertex closer to the origin than we were (i.e. we took the skew-edge).","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"As it turns out these conditions can be combined together to say that","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"we backtrack whenever the distance of the current state to the origin is","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"shorter than the length of the history tape.","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"This mechanism is implemented in Automata.BacktrackSearch.","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"With this, instead of examining k² pairs for suffix-prefix intersections it is enouth to perform k backtrack searches (where k is the number of rules of our rws). In pseudocode","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"function check_confluence(rws::RewritingSystem{W}, idxA::IndexAutomaton) where W\n    stack = Vector{Tupe{W,W}}()\n    backtrack = Automata.BacktrackSearch(idxA)\n\n    # ... initialize some temporary structures here\n    for ri in rules(rws)\n        stack = find_critical_pairs!(stack, backtrack, ri, ...)\n        !isempty(stack) && break\n        # i.e. we found some honest failures to local confluence\n    end\n    return stack\nend","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"If you inspect the actual code, you will be surprised how close it is to the listing above.","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"find_critical_pairs!(stack, ::Automata.BacktrackSearch, ::Rule, ::Workspace)","category":"page"},{"location":"knuthbendix_idxA/#KnuthBendix.find_critical_pairs!-Tuple{Any, KnuthBendix.Automata.BacktrackSearch, KnuthBendix.Rule, KnuthBendix.Workspace}","page":"Using index automaton","title":"KnuthBendix.find_critical_pairs!","text":"find_critical_pairs!(stack, bts, rule, work[; max_age])\n\nFind critical pairs by completing lhs of rule by backtrack search on index automaton.\n\nIf rule can be written as P → Q this function performs a backtrack search on bts.automaton to find possible completions of P[2:end] to a word which ends with P' where P' → Q' is another rule. The search backtracks when its depth is greater than or equal to the length of P' to make sure that P and P' share an overlap (i.e. a nonempty suffix of P is a prefix of P')\n\n\n\n\n\n","category":"method"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"[Sims1994]: Charles C. Sims Computation with finitely presented groups,          Cambridge University Press, 1994.","category":"page"},{"location":"knuthbendix_idxA/","page":"Using index automaton","title":"Using index automaton","text":"[Aho1975]: Alfred V. Aho and Margaret J. Corasick Efficient string matching: an aid to bibliographic search Commun. ACM 18, 6 (June 1975), 333–340. doi:10.1145/360825.360855","category":"page"},{"location":"nc_groebner/#Non-commutative-Gröbner-bases","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"","category":"section"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"Here is a small example how this package can be useful outside of the realm of the theory of finitely presented monoids. Finding a normal form for polynomial algebras","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"mathbbKlangle x_1 ldots x_nranglebig\n(f_1(x_1ldots x_n) ldots f_k(x_1 ldots x_n))","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"in non-commutative variables modulo certain polynomial equations is a standard problem that can be solved via the computation the non-commutative Gröbner basis. For an example of such approach see GAP package gbnp. It is curious that the majority (but not all!) of the examples listed in Appendix A are generated by a set of equations which equate one monomial to some other, i.e. all f_i(x_1 ldots x_n) are of the form m_1 = kcdot m_2 where m_i are simply monomials in variables x_1 ldots x_n and k in mathbbK.","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"To compute normal forms in such (associative) algebras it is enough to rephrase the problem as a problem of finding the normal form in monoid algebra, with monoid generated by x_1 ldots x_n possibly extended by zero and a finite set of units from mathbbK.","category":"page"},{"location":"nc_groebner/#Physics-inspired-example","page":"Non-commutative Gröbner bases","title":"Physics inspired example","text":"","category":"section"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"The example is derived from a description of relations between spin variables. In short we have three sets of variables (sigma^x)_i, (sigma^y)_i and (sigma^z)_i for i in 1 ldots L. These variables satisfy the following relations (here \\mathbf{i} denotes the complex unit):","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"beginaligned\n(sigma^a)_i^2  = 1 i=1ldotsL ain xyz\n(sigma^x)_i (sigma^y)_i = mathbfi(sigma^z)_i  i=1ldotsL\n(sigma^y)_i (sigma^z)_i = mathbfi(sigma^x)_i  i=1ldotsL\n(sigma^z)_i (sigma^x)_i = mathbfi(sigma^y)_i  i=1ldotsL\n(sigma^a)_i (sigma^b)_j = (sigma^b)_j (sigma^a)_i  1 leq ineq j leq L ain xyz\nendaligned","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"Moreover we require anticommutativity of (sigma^a)_i and (sigma^b)_i, i.e. if (sigma^a)_i (sigma^b)_i = mathbfi(sigma^c)_i, then (sigma^b)_i (sigma^a)_i = -mathbfi(sigma^c)_i, but as we shall see, this already follows from the the rules.","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"If we treat mathbfi as an additional variable commuting with every (sigma^a)_i, then all of these rules equate one monomial to another and the computation of the normal form is therefore suitable for Knuth-Bendix completion!. Let's have a look how one could implement this.","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"CurrentModule = KnuthBendix\nDocTestSetup  = quote\n    using KnuthBendix\nend","category":"page"},{"location":"nc_groebner/#The-alphabet","page":"Non-commutative Gröbner bases","title":"The alphabet","text":"","category":"section"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"Let us begin with an alphabet:","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"julia> L = 4\n4\n\njulia> subscript = [\"₁\", \"₂\",\"₃\",\"₄\",\"₅\",\"₆\",\"₇\",\"₈\",\"₉\",\"₀\"];\n\njulia> Sσˣ = [Symbol(:σˣ, subscript[i]) for i in 1:L]\n4-element Vector{Symbol}:\n :σˣ₁\n :σˣ₂\n :σˣ₃\n :σˣ₄\n\njulia> Sσʸ = [Symbol(:σʸ, subscript[i]) for i in 1:L];\n\njulia> Sσᶻ = [Symbol(:σᶻ, subscript[i]) for i in 1:L];\n\njulia> SI = Symbol(:I); # the complex unit\n\njulia> letters = [SI; Sσˣ; Sσʸ; Sσᶻ];\n\njulia> A = Alphabet(letters, [0; 2:length(letters)])\nAlphabet of Symbol\n  1. I\n  2. σˣ₁  (self-inverse)\n  3. σˣ₂  (self-inverse)\n  4. σˣ₃  (self-inverse)\n  5. σˣ₄  (self-inverse)\n  6. σʸ₁  (self-inverse)\n  7. σʸ₂  (self-inverse)\n  8. σʸ₃  (self-inverse)\n  9. σʸ₄  (self-inverse)\n 10. σᶻ₁  (self-inverse)\n 11. σᶻ₂  (self-inverse)\n 12. σᶻ₃  (self-inverse)\n 13. σᶻ₄  (self-inverse)\n","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"Now let's define words with just those letters, so that we can use them as generators in the free monoid over A:","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"julia> I = Word([A[SI]])\nWord{UInt16}: 1\n\njulia> σˣ = [Word([A[s]]) for s in Sσˣ];\n\njulia> σʸ = [Word([A[s]]) for s in Sσʸ];\n\njulia> σᶻ = [Word([A[s]]) for s in Sσᶻ];\n","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"Note that I has no inverse among letters while all other are self-inverse.","category":"page"},{"location":"nc_groebner/#Rewriting-System","page":"Non-commutative Gröbner bases","title":"Rewriting System","text":"","category":"section"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"Let us define our relations now","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"julia> complex_unit = [I^4 => one(I)]\n1-element Vector{Pair{Word{UInt16}, Word{UInt16}}}:\n 1·1·1·1 => (id)\n\njulia> Σ = [σˣ, σʸ, σᶻ];\n\njulia> complex_unit = [I^4 => one(I)]\n1-element Vector{Pair{Word{UInt16}, Word{UInt16}}}:\n 1·1·1·1 => (id)\n\njulia> # squares are taken care of by the inverses in the alphabet\n       # squares = [a*a=>one(a) for a in [σˣ;σʸ;σᶻ]]\n       cyclic = [\n            σᵃ[i]*σᵇ[i] => I*σᶜ[i] for i in 1:L\n                for (σᵃ, σᵇ, σᶜ) in (Σ, circshift(Σ,1), circshift(Σ,2))\n            ]\n12-element Vector{Pair{Word{UInt16}, Word{UInt16}}}:\n  2·6 => 1·10\n 10·2 => 1·6\n 6·10 => 1·2\n  3·7 => 1·11\n 11·3 => 1·7\n 7·11 => 1·3\n  4·8 => 1·12\n 12·4 => 1·8\n 8·12 => 1·4\n  5·9 => 1·13\n 13·5 => 1·9\n 9·13 => 1·5\n\njulia> commutations = [\n               σᵃ[i]*σᵇ[j] => σᵇ[j]*σᵃ[i] for σᵃ in Σ for σᵇ in Σ\n               for i in 1:L for j in 1:L if i ≠ j\n           ];\n\njulia> append!(commutations,\n        # I commutes with everything, since it comes from the field\n            [σ[i]*I => I*σ[i] for σ in Σ for i in 1:L],\n        )\n120-element Vector{Pair{Word{UInt16}, Word{UInt16}}}:\n  2·3 => 3·2\n  2·4 => 4·2\n  2·5 => 5·2\n  3·2 => 2·3\n  3·4 => 4·3\n  3·5 => 5·3\n  4·2 => 2·4\n  4·3 => 3·4\n  4·5 => 5·4\n  5·2 => 2·5\n      ⋮\n  5·1 => 1·5\n  6·1 => 1·6\n  7·1 => 1·7\n  8·1 => 1·8\n  9·1 => 1·9\n 10·1 => 1·10\n 11·1 => 1·11\n 12·1 => 1·12\n 13·1 => 1·13\n\njulia> rws = RewritingSystem([complex_unit; cyclic; commutations], LenLex(A));\n\njulia> rwsC = knuthbendix(rws)\nRewriting System with 507 active rules ordered by LenLex: I < σˣ₁ < σˣ₂ < σˣ₃ < σˣ₄ < σʸ₁ < σʸ₂ < σʸ₃ < σʸ₄ < σᶻ₁ < σᶻ₂ < σᶻ₃ < σᶻ₄:\n┌──────┬──────────────────────────────────┬──────────────────────────────────┐\n│ Rule │                              lhs │ rhs                              │\n├──────┼──────────────────────────────────┼──────────────────────────────────┤\n│    1 │                            σˣ₁^2 │ (id)                             │\n│    2 │                            σˣ₂^2 │ (id)                             │\n│    3 │                            σˣ₃^2 │ (id)                             │\n│    4 │                            σˣ₄^2 │ (id)                             │\n│    5 │                            σʸ₁^2 │ (id)                             │\n│    6 │                            σʸ₂^2 │ (id)                             │\n│    7 │                            σʸ₃^2 │ (id)                             │\n│    8 │                            σʸ₄^2 │ (id)                             │\n│    9 │                            σᶻ₁^2 │ (id)                             │\n│   10 │                            σᶻ₂^2 │ (id)                             │\n│   11 │                            σᶻ₃^2 │ (id)                             │\n│   12 │                            σᶻ₄^2 │ (id)                             │\n│   13 │                          σˣ₁*σʸ₁ │ I*σᶻ₁                            │\n│  ⋮   │                ⋮                 │                ⋮                 │\n└──────┴──────────────────────────────────┴──────────────────────────────────┘\n                                                              494 rows omitted\n","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"Previously we stated that the anticommutativity should hold, i.e. if","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"(sigma^a)_i (sigma^b)_i (sigma^c)_i = mathbfiquad textthen quad\n(sigma^b)_i (sigma^a)_i (sigma^c)_i = -mathbfi = mathbfi^3","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"Let us check this now.","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"julia> KnuthBendix.rewrite(σʸ[1]*σˣ[1], rwsC)\nWord{UInt16}: 6·2\n\njulia> KnuthBendix.rewrite(I^3*σᶻ[1], rwsC)\nWord{UInt16}: 6·2\n","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"Indeed, rewriting brings both of the words to the same form, so they must represent the same element in the monoid.","category":"page"},{"location":"nc_groebner/#Weighting-the-letters","page":"Non-commutative Gröbner bases","title":"Weighting the letters","text":"","category":"section"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"If we want to force normalforms to begin with I (if a word with such presentation represents the given monomial) we could use WeightedLex ordering, weighting other letters disproportionally higher than w, e.g.","category":"page"},{"location":"nc_groebner/","page":"Non-commutative Gröbner bases","title":"Non-commutative Gröbner bases","text":"julia> wLA = WeightedLex(A, weights = [1; [1000 for _ in 2:length(A)]])\nWeightedLex: I(1) < σˣ₁(1000) < σˣ₂(1000) < σˣ₃(1000) < σˣ₄(1000) < σʸ₁(1000) < σʸ₂(1000) < σʸ₃(1000) < σʸ₄(1000) < σᶻ₁(1000) < σᶻ₂(1000) < σᶻ₃(1000) < σᶻ₄(1000)\n\njulia> rws2 = RewritingSystem([complex_unit; cyclic; commutations], wLA);\n\njulia> rwsC2 = knuthbendix(rws2)\nRewriting System with 263 active rules ordered by WeightedLex: I(1) < σˣ₁(1000) < σˣ₂(1000) < σˣ₃(1000) < σˣ₄(1000) < σʸ₁(1000) < σʸ₂(1000) < σʸ₃(1000) < σʸ₄(1000) < σᶻ₁(1000) < σᶻ₂(1000) < σᶻ₃(1000) < σᶻ₄(1000):\n┌──────┬──────────────────────────────────┬──────────────────────────────────┐\n│ Rule │                              lhs │ rhs                              │\n├──────┼──────────────────────────────────┼──────────────────────────────────┤\n│    1 │                            σˣ₁^2 │ (id)                             │\n│    2 │                            σˣ₂^2 │ (id)                             │\n│    3 │                            σˣ₃^2 │ (id)                             │\n│    4 │                            σˣ₄^2 │ (id)                             │\n│    5 │                            σʸ₁^2 │ (id)                             │\n│    6 │                            σʸ₂^2 │ (id)                             │\n│    7 │                            σʸ₃^2 │ (id)                             │\n│    8 │                            σʸ₄^2 │ (id)                             │\n│    9 │                            σᶻ₁^2 │ (id)                             │\n│   10 │                            σᶻ₂^2 │ (id)                             │\n│   11 │                            σᶻ₃^2 │ (id)                             │\n│   12 │                            σᶻ₄^2 │ (id)                             │\n│   13 │                          σˣ₁*σʸ₁ │ I*σᶻ₁                            │\n│  ⋮   │                ⋮                 │                ⋮                 │\n└──────┴──────────────────────────────────┴──────────────────────────────────┘\n                                                              250 rows omitted\n\n\njulia> KnuthBendix.rewrite(σʸ[1]*σˣ[1], rwsC2)\nWord{UInt16}: 1·1·1·10\n\njulia> KnuthBendix.print_repr(stdout, ans, A)\nI^3*σᶻ₁\n","category":"page"},{"location":"knuthbendix1/#Naive","page":"Naive","title":"Naive","text":"","category":"section"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"This version is a simplistic implementation of the completion that is terrible to run and great for understanding the general idea. This version follows closely procedure KBS_1 from Section 2.5[Sims1994].","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"Below is a julia-flavoured pseudocode describing the completion procedure.","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"function knuthbendix1(rws::RewritingSystem; kwargs...)\n    for ri in rules(rws)\n        for rj in rules(rws)\n            forceconfluence!(rws, ri, rj)\n            ri == rj && break\n            forceconfluence!(rws, rj, ri)\n        end\n        # Maybe some checks here, etc.\n    end\n    return rws\nend","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"CurrentModule = KnuthBendix","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"Here forceconfluence! finds all potential failures to local confluence in rws that arise as intersection of rules ri and rj, and deriverule! resolves them. This means that all suffix-prefix words are identified (see Local confluence and suffix-prefix words) and the appropriate rules to resolve the failures in rewriting are pushed to rws. This extends[1] the iteration over rules(rws) and the outer loop becomes longer.","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"An important feature is that while the outer loop (for ri in rules(rws)) is potentially infinite, the inner one (for rj in rules(rws)) is always broken after a finite number of steps. We therefore traverse (potentially) doubly infinite iteration space in finite chunks which guarantees that each pair of rules will be considered after a finite amount of time. Completion even for very simple rewriting systems may fail if this condition is not observed.","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"As a side-effect we may choose to run some checks etc. after the inner loop is and we could e.g. decide to quit early (if things go out of hand) or do something else.","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"knuthbendix1\nforceconfluence!(rws::RewritingSystem, ::Any, ::Any)\nderiverule!(rws::RewritingSystem, ::AbstractWord, ::AbstractWord)\nreduce!(::KBS1AlgPlain, ::RewritingSystem)","category":"page"},{"location":"knuthbendix1/#KnuthBendix.knuthbendix1","page":"Naive","title":"KnuthBendix.knuthbendix1","text":"knuthbendix1(rws::RewritingSystem; max_rules=100, kwargs...)\n\nRun the Knuth-Bendix procedure that (if successful) yields the reduced, confluent rewriting system generated by rules of rws.\n\nThis is a simplistic implementation for educational purposes only. It follows closely KBS_1 procedure as described in Section 2.5[Sims1994], p. 68.\n\nwarning: Warning\nForced termination takes place after the number of rules stored in the RewritingSystem exceeds max_rules.\n\n[Sims1994]: Charles C. Sims Computation with finitely presented groups,          Cambridge University Press, 1994.\n\n\n\n\n\n","category":"function"},{"location":"knuthbendix1/#KnuthBendix.forceconfluence!-Tuple{RewritingSystem, Any, Any}","page":"Naive","title":"KnuthBendix.forceconfluence!","text":"forceconfluence!(rws::RewritingSystem, r₁, r₂)\n\nExamine overlaps of left hand sides of rules r₁ and r₂ to find (potential) failures to local confluence. New rules are added to assure local confluence if necessary.\n\nSuppose that r₁ = (lhs₁ → rhs₂) and r₂ = (lhs₂ → rhs₂). This function tries to write lhs₁ = a·b and lhs₂ = b·c so that word a·b·c can be rewritten in two potentially different ways:\n\n       a·b·c\n       /   \\\n      /     \\\nrhs₁·c    a·rhs₂\n\nthus a (potentially) critical pair (rhs₁·c, a·rhs₂) needs to be resolved in the rewriting system.\n\nIt is not assumed that rws is reduced, and therefore also the case when lhs₁ = a·lhs₂·c with non-trivial c is examined.\n\nSee procedure OVERLAP_1 in [Sims1994], p. 69.\n\n[Sims1994]: Charles C. Sims Computation with finitely presented groups,          Cambridge University Press, 1994.\n\n\n\n\n\n","category":"method"},{"location":"knuthbendix1/#KnuthBendix.deriverule!-Tuple{RewritingSystem, KnuthBendix.Words.AbstractWord, KnuthBendix.Words.AbstractWord}","page":"Naive","title":"KnuthBendix.deriverule!","text":"deriverule!(rws::RewritingSystem, u::AbstractWord, v::AbstractWord)\n\nGiven a critical pair (u, v) with respect to rws adds a rule to rws (if necessary) that resolves the pair, i.e. makes rws locally confluent with respect to (u,v). See [Sims1994], p. 69.\n\n[Sims1994]: Charles C. Sims Computation with finitely presented groups,          Cambridge University Press, 1994.\n\n\n\n\n\n","category":"method"},{"location":"knuthbendix1/#KnuthBendix.reduce!-Tuple{KnuthBendix.KBS1AlgPlain, RewritingSystem}","page":"Naive","title":"KnuthBendix.reduce!","text":"reduce!(::NaiveKBS1Alg, rws::RewritingSystem)\n\nBring rws to its reduced form using the naive algorithm.\n\nThe returned system consists of rules p → rewrite(p, rws) for p in irreduciblesubsystem(rws).\n\n\n\n\n\n","category":"method"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"[1]: If you don't like changing the structure while iterating over it you are   not alone, but sometimes it is the easiest things to do.","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"[Sims1994]: Charles C. Sims Computation with finitely presented groups,          Cambridge University Press, 1994.","category":"page"},{"location":"knuthbendix1/#Example-from-theoretical-section","page":"Naive","title":"Example from theoretical section","text":"","category":"section"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"To reproduce the computations of the Example one could call knuthbendix1 with verbosity=2 which prints step-by-step information.","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"CurrentModule = KnuthBendix\nDocTestSetup  = quote\n    using KnuthBendix\nend\nDocTestFilters = r\"┌ Warning.*\\n└ @ KnuthBendix.*\\n\"","category":"page"},{"location":"knuthbendix1/","page":"Naive","title":"Naive","text":"julia> alph = Alphabet([:a,:A,:b],[2,1,0])\nAlphabet of Symbol\n  1. a    (inverse of: A)\n  2. A    (inverse of: a)\n  3. b\n\njulia> a,A,b = [Word([i]) for i in 1:length(alph)]\n3-element Vector{Word{UInt16}}:\n Word{UInt16}: 1\n Word{UInt16}: 2\n Word{UInt16}: 3\n\njulia> rules = [b^3=>one(b), a*b => b*a]\n2-element Vector{Pair{Word{UInt16}, Word{UInt16}}}:\n 3·3·3 => (id)\n   1·3 => 3·1\n\njulia> rws = RewritingSystem(rules, LenLex(alph))\nRewriting System with 4 active rules ordered by LenLex: a < A < b:\n┌──────┬──────────────────────────────────┬──────────────────────────────────┐\n│ Rule │                              lhs │ rhs                              │\n├──────┼──────────────────────────────────┼──────────────────────────────────┤\n│    1 │                              a*A │ (id)                             │\n│    2 │                              A*a │ (id)                             │\n│    3 │                              b^3 │ (id)                             │\n│    4 │                              b*a │ a*b                              │\n└──────┴──────────────────────────────────┴──────────────────────────────────┘\n\njulia> KnuthBendix.knuthbendix1(rws, verbosity = 2)\n┌ Warning: knuthbendix1 is a simplistic implementation for educational purposes only.\n└ @ KnuthBendix ~/.julia/dev/KnuthBendix/src/knuthbendix1.jl:146\n[ Info: consider (1, 1) for critical pairs\n[ Info: consider (2, 1) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (2·1 ⇒ (id), 1·2 ⇒ (id))\n│   (a, b, c) = (2, 1, 2)\n└   pair = (2, 2)\n[ Info: pair does not fail local confluence, both sides rewrite to 2\n[ Info: consider (1, 2) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (1·2 ⇒ (id), 2·1 ⇒ (id))\n│   (a, b, c) = (1, 2, 1)\n└   pair = (1, 1)\n[ Info: pair does not fail local confluence, both sides rewrite to 1\n[ Info: consider (2, 2) for critical pairs\n[ Info: consider (3, 1) for critical pairs\n[ Info: consider (1, 3) for critical pairs\n[ Info: consider (3, 2) for critical pairs\n[ Info: consider (2, 3) for critical pairs\n[ Info: consider (3, 3) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (3·3·3 ⇒ (id), 3·3·3 ⇒ (id))\n│   (a, b, c) = (3·3, 3, 3·3)\n└   pair = (3·3, 3·3)\n[ Info: pair does not fail local confluence, both sides rewrite to 3·3\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (3·3·3 ⇒ (id), 3·3·3 ⇒ (id))\n│   (a, b, c) = (3, 3·3, 3)\n└   pair = (3, 3)\n[ Info: pair does not fail local confluence, both sides rewrite to 3\n[ Info: consider (4, 1) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (3·1 ⇒ 1·3, 1·2 ⇒ (id))\n│   (a, b, c) = (3, 1, 2)\n└   pair = (1·3·2, 3)\n[ Info: pair fails local confluence, rewrites to 1·3·2 ≠ 3\n[ Info: adding rule [ 5. a*b*A\t → \tb ] to rws\n[ Info: consider (1, 4) for critical pairs\n[ Info: consider (4, 2) for critical pairs\n[ Info: consider (2, 4) for critical pairs\n[ Info: consider (4, 3) for critical pairs\n[ Info: consider (3, 4) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (3·3·3 ⇒ (id), 3·1 ⇒ 1·3)\n│   (a, b, c) = (3·3, 3, 1)\n└   pair = (1, 3·3·1·3)\n[ Info: pair does not fail local confluence, both sides rewrite to 1\n[ Info: consider (4, 4) for critical pairs\n[ Info: consider (5, 1) for critical pairs\n[ Info: consider (1, 5) for critical pairs\n[ Info: consider (5, 2) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (1·3·2 ⇒ 3, 2·1 ⇒ (id))\n│   (a, b, c) = (1·3, 2, 1)\n└   pair = (3·1, 1·3)\n[ Info: pair does not fail local confluence, both sides rewrite to 1·3\n[ Info: consider (2, 5) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (2·1 ⇒ (id), 1·3·2 ⇒ 3)\n│   (a, b, c) = (2, 1, 3·2)\n└   pair = (3·2, 2·3)\n[ Info: pair fails local confluence, rewrites to 3·2 ≠ 2·3\n[ Info: adding rule [ 6. b*A\t → \tA*b ] to rws\n[ Info: consider (5, 3) for critical pairs\n[ Info: consider (3, 5) for critical pairs\n[ Info: consider (5, 4) for critical pairs\n[ Info: consider (4, 5) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (3·1 ⇒ 1·3, 1·3·2 ⇒ 3)\n│   (a, b, c) = (3, 1, 3·2)\n└   pair = (1·3·3·2, 3·3)\n[ Info: pair does not fail local confluence, both sides rewrite to 3·3\n[ Info: consider (5, 5) for critical pairs\n[ Info: consider (6, 1) for critical pairs\n[ Info: consider (1, 6) for critical pairs\n[ Info: consider (6, 2) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (3·2 ⇒ 2·3, 2·1 ⇒ (id))\n│   (a, b, c) = (3, 2, 1)\n└   pair = (2·3·1, 3)\n[ Info: pair does not fail local confluence, both sides rewrite to 3\n[ Info: consider (2, 6) for critical pairs\n[ Info: consider (6, 3) for critical pairs\n[ Info: consider (3, 6) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (3·3·3 ⇒ (id), 3·2 ⇒ 2·3)\n│   (a, b, c) = (3·3, 3, 2)\n└   pair = (2, 3·3·2·3)\n[ Info: pair does not fail local confluence, both sides rewrite to 2\n[ Info: consider (6, 4) for critical pairs\n[ Info: consider (4, 6) for critical pairs\n[ Info: consider (6, 5) for critical pairs\n[ Info: consider (5, 6) for critical pairs\n┌ Info: lhs₁ suffix-prefix lhs₂:\n│   rules = (1·3·2 ⇒ 3, 3·2 ⇒ 2·3)\n│   (a, b, c) = (1, 3·2, (id))\n└   pair = (3, 1·2·3)\n[ Info: pair does not fail local confluence, both sides rewrite to 3\n[ Info: consider (6, 6) for critical pairs\nRewriting System with 5 active rules ordered by LenLex: a < A < b:\n┌──────┬──────────────────────────────────┬──────────────────────────────────┐\n│ Rule │                              lhs │ rhs                              │\n├──────┼──────────────────────────────────┼──────────────────────────────────┤\n│    1 │                              a*A │ (id)                             │\n│    2 │                              A*a │ (id)                             │\n│    3 │                              b^3 │ (id)                             │\n│    4 │                              b*a │ a*b                              │\n│    5 │                              b*A │ A*b                              │\n└──────┴──────────────────────────────────┴──────────────────────────────────┘\n","category":"page"},{"location":"rewriting_system/#Rewriting-System","page":"Rewriting System","title":"Rewriting System","text":"","category":"section"},{"location":"rewriting_system/","page":"Rewriting System","title":"Rewriting System","text":"It's just a struct that holds things together required for Knuth-Bendix completion.","category":"page"},{"location":"rewriting_system/","page":"Rewriting System","title":"Rewriting System","text":"CurrentModule = KnuthBendix","category":"page"},{"location":"rewriting_system/","page":"Rewriting System","title":"Rewriting System","text":"RewritingSystem\n\nrules(::RewritingSystem)\nordering(::RewritingSystem)\nalphabet(::RewritingSystem)\nisirreducible(::AbstractWord, ::RewritingSystem)\nirreduciblesubsystem(::RewritingSystem)\ncheck_confluence\nisconfluent\nreduce!(::RewritingSystem, ::Workspace)","category":"page"},{"location":"rewriting_system/#KnuthBendix.RewritingSystem","page":"Rewriting System","title":"KnuthBendix.RewritingSystem","text":"RewritingSystem{W<:AbstractWord, O<:Ordering}\nRewritingSystem(rwrules::Vector{Pair{W,W}}, order, bare=false)\n\nRewritingSystem holds the list of ordered (by order) rewriting rules of W<:AbstractWords.\n\n\n\n\n\n","category":"type"},{"location":"rewriting_system/#KnuthBendix.rules-Tuple{RewritingSystem}","page":"Rewriting System","title":"KnuthBendix.rules","text":"rules(rws::RewritingSystem)\n\nReturn the iterator over active rewriting rules.\n\n\n\n\n\n","category":"method"},{"location":"rewriting_system/#KnuthBendix.ordering-Tuple{RewritingSystem}","page":"Rewriting System","title":"KnuthBendix.ordering","text":"ordering(rws::RewritingSystem)\n\nReturn the ordering of the rewriting system.\n\n\n\n\n\n","category":"method"},{"location":"rewriting_system/#KnuthBendix.alphabet-Tuple{RewritingSystem}","page":"Rewriting System","title":"KnuthBendix.alphabet","text":"alphabet(rws::RewritingSystem)\n\nReturn the underlying Alphabet of the rewriting system.\n\n\n\n\n\n","category":"method"},{"location":"rewriting_system/#KnuthBendix.isirreducible-Tuple{KnuthBendix.Words.AbstractWord, RewritingSystem}","page":"Rewriting System","title":"KnuthBendix.isirreducible","text":"isirreducible(w::AbstractWord, rws::RewritingSystem)\n\nReturns whether a word is irreducible with respect to a given rewriting system\n\n\n\n\n\n","category":"method"},{"location":"rewriting_system/#KnuthBendix.irreduciblesubsystem-Tuple{RewritingSystem}","page":"Rewriting System","title":"KnuthBendix.irreduciblesubsystem","text":"irreduciblesubsystem(rws::RewritingSystem)\n\nReturn an array of left sides of rules from rewriting system of which all the proper subwords are irreducible with respect to this rewriting system.\n\n\n\n\n\n","category":"method"},{"location":"rewriting_system/#KnuthBendix.check_confluence","page":"Rewriting System","title":"KnuthBendix.check_confluence","text":"check_confluence(rws::RewritingSystem)\n\nCheck if a reduced rewriting system is confluent.\n\nReturn a stack of critical pairs. While the stack is by no means an exhaustive list of critical pairs, empty stack is returned if and only if rws is confluent.\n\nThere is also a modifying version check_confluence!.\n\n\n\n\n\n","category":"function"},{"location":"rewriting_system/#KnuthBendix.isconfluent","page":"Rewriting System","title":"KnuthBendix.isconfluent","text":"isconfluent(rws::RewritingSystem)\n\nCheck if a rewriting system is confluent.\n\nThe check follows first by reducing rws using KBS2AlgPlain(), and then constructing its index automaton and running backtrack search for all rules of the system.\n\nnote: Note\nisconfluent may modify rws if it is not already reduced.\n\n\n\n\n\n","category":"function"},{"location":"rewriting_system/#KnuthBendix.reduce!-Tuple{RewritingSystem, KnuthBendix.Workspace}","page":"Rewriting System","title":"KnuthBendix.reduce!","text":"reduce!(rws::RewritingSystem[, work=Workspace(rws); kwargs...])\n\nReduce the rewriting system in-place using the default algorithm\n\nCurrently the default algorithm is KBS2AlgPlain(), see reduce!(::KBS2AlgPlain, ...).\n\n\n\n\n\n","category":"method"},{"location":"alphabets/#Alphabets","page":"Alphabets","title":"Alphabets","text":"","category":"section"},{"location":"alphabets/","page":"Alphabets","title":"Alphabets","text":"Alphabet\n\nKnuthBendix.setinverse!\nKnuthBendix.hasinverse\ninv(x, ::Alphabet)\ninv(::KnuthBendix.AbstractWord, ::Alphabet)","category":"page"},{"location":"alphabets/#KnuthBendix.Alphabet","page":"Alphabets","title":"KnuthBendix.Alphabet","text":"Alphabet(letters::AbstractVector[, inversions])\n\nAn alphabet consists of the symbols of a common type T.\n\nAn Alphabet defines a bijection between consecutive integers and its letters, i.e. it can be queried for the index of a letter, or the letter corresponding to a given index.\n\nExample\n\njulia> al = Alphabet([:a, :b, :c])\nAlphabet of Symbol\n  1. a\n  2. b\n  3. c\n\njulia> al[2]\n:b\n\njulia> al[:c]\n3\n\njulia> Alphabet([:a, :A, :b], [2, 1, 0])\nAlphabet of Symbol\n  1. a    (inverse of: A)\n  2. A    (inverse of: a)\n  3. b\n\n\n\n\n\n","category":"type"},{"location":"alphabets/#KnuthBendix.setinverse!","page":"Alphabets","title":"KnuthBendix.setinverse!","text":"setinverse!(A::Alphabet{T}, x::T, X::T) where T\n\nSet the inversion of x to X (and vice versa).\n\nExample\n\njulia> al = Alphabet([:a, :b, :c])\nAlphabet of Symbol\n  1. a\n  2. b\n  3. c\n\njulia> KnuthBendix.setinverse!(al, :a, :c)\nAlphabet of Symbol\n  1. a    (inverse of: c)\n  2. b\n  3. c    (inverse of: a)\n\njulia> KnuthBendix.setinverse!(al, :a, :b)\n┌ Warning: a already has an inverse: c; overriding\n└ @ KnuthBendix ~/.julia/dev/KnuthBendix/src/alphabets.jl:157\nAlphabet of Symbol\n  1. a    (inverse of: b)\n  2. b    (inverse of: a)\n  3. c\n\n\n\n\n\n","category":"function"},{"location":"alphabets/#KnuthBendix.hasinverse","page":"Alphabets","title":"KnuthBendix.hasinverse","text":"hasinverse(idx::Integer, A::Alphabet)\nhasinverse(letter, A::Alphabet)\n\nCheck if alphabet A defines the inverse of letter.\n\n\n\n\n\n","category":"function"},{"location":"alphabets/#Base.inv-Tuple{Any, Alphabet}","page":"Alphabets","title":"Base.inv","text":"inv(idx::Integer, A::Alphabet)\ninv(letter::Integer, A::Alphabet)\n\nReturn the inverse of a letter letter in the context of alphabet A.\n\nIf hasinverse(letter, A) == false a DomainError is thrown.\n\n\n\n\n\n","category":"method"},{"location":"alphabets/#Base.inv-Tuple{KnuthBendix.Words.AbstractWord, Alphabet}","page":"Alphabets","title":"Base.inv","text":"inv(w::AbstractWord, A::Alphabet)\n\nReturn the inverse of a word w in the context of alphabet A.\n\n\n\n\n\n","category":"method"},{"location":"theory/#Monoids-and-the-word-problem","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"","category":"section"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"This package implements Knuth-Bendix completion of a rewriting system derived from a presentation of a monoid.","category":"page"},{"location":"theory/#Monoids-and-their-presentations","page":"Monoids and the word problem","title":"Monoids and their presentations","text":"","category":"section"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"In general one starts with an alphabet mathcalA, creates a free monoid mathcalA^* (the set of all words over the alphabet, with concatenation) and then forms a quotient of mathcalA^* by a congruence R  mathcalA^*times mathcalA^* Recall that a congruence on a monoid is an equivalence relation whose equivalence classes are preserved by monoid multiplication. Under this assumption the quotient inherits the structure of a quotient monoid Q = mathcalA^*R.","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"In the case of a congruence on a group, the equivalence class of the (group) identity 1 is a normal subgroup, and each equivalence class of R is a shift of it (these are cosets). As it is well known, the quotient Q inherits the group structure. In monoids, however, congruences are not necessarily determined by 1 only.","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"One usually does not have the full set of equivalence classes at their disposal, but only a small set of pairs in relation that generate the congruence. This is traditionally written as a monoid presentation langle mathcalA mid R rangle, e.g.: M = langle x X y mid xcdot X = Xcdot x =varepsilon xy = yx rangle Here by xcdot X = varepsilon we mean that R contains the pair (xcdot X varepsilon) (the latter denoting the trivial element of mathcalA^*, i.e. the empty word) and R is the smallest congruence on mathcalA^* which contains the pairs indicated by the equations.","category":"page"},{"location":"theory/#Word-Problem","page":"Monoids and the word problem","title":"Word Problem","text":"","category":"section"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"One of the most natural problems in this setting is to determine when do two words in mathcalA^* represent the same element of M, i.e. belong to the same congruence class of R. This is the famous (unsolvable in general) word problem:","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"note: Word Problem\nWhen do words v and w from mathcalA^* represent the same element of M?","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"Is it unsolvable though? Here is a somehow trivial solution of the word problem using the axiom of choice:","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"tip: Solution using AC\nBy the axiom of choice we could pick a distinguished element from every congruence class of R. Given v let v subset mathcalA^* denote its congruence class and v_0 the corresponding distinguished element. Similarly we could find the element w_0 in w in the congruence class of w. The words represent the same element if and only if v_0 = w_0.","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"The unsolvability of the Word Problem is rather caused by the very specific model of computations (i.e. Turing machine) rather than unsolvability in the sense of providing a solution using broadly accepted mathematics.","category":"page"},{"location":"theory/#Normal-forms-and-rewriting-systems","page":"Monoids and the word problem","title":"Normal forms and rewriting systems","text":"","category":"section"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"The choice of a distinguished element from each congruence class is sometimes referred to as the choice of a normal form (or canonical form) for R. If we could compute the normal form without referring to axiom of choice, we could solve the word problem.","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"A particular approach to normal forms is given by rewriting systems. To begin we need not only the set of pairs but also a rewriting ordering i.e. a bi-invariant well-ordering of mathcalA^*. For the first reading you may think of ordering words by length and then by lexicographical order - it is a valid example of rewriting ordering. Such set of pairs and the order is called the rewriting system mathcalR(R ). One usually thinks in this context of element of R as rewriting equations p to q, where p is always greater than q according to the order.","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"The process of rewriting then follows by finding in w = w_n any word p (as a subword) which is a left hand side of a rule p to q in mathcalR and replacing it with q to obtain w_n-1. By the bi-invariance this process forms a decreasing sequence of words","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"w=w_n  w_n-1  cdots  w_1  w_0","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"which must end after a finite number of rewrites (since  is a well-ordering). Since applying rewriting rules doesn't change the congruence class w_0 is congruent to the initial w. Then we could proclaim w_0 to be the normal form for w. Unfortunately things are not so simple. The process of rewriting depends heavily on the order in which rules were used and on the positions where the matches of the left hand sides were found (note also that matches may overlap).","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"A rewriting system for which those choices don't matter is called confluent. Confluence of mathcalR means that effectively w_0 is the least element in the congruence class, which makes it a perfect choice for normal form!","category":"page"},{"location":"theory/","page":"Monoids and the word problem","title":"Monoids and the word problem","text":"The main purpose of the Knuth-Bendix completion is to bring any rewriting system mathcalR to confluence (see the next chapter). In other words the Knuth-Bendix completion transforms the initial set of pairs generating congruence R (and an order  on mathcalA^*) into a rewriting system mathcalR that computes the normal form in a constructive, deterministic fashion.","category":"page"},{"location":"knuthbendix2/#Using-a-stack","page":"Using a stack","title":"Using a stack","text":"","category":"section"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"As can be observed in Knuth Bendix completion - an example after we have added rule 6, there was no point considering rule 5, since it was rendered redundant. This can be achieved by keeping a boolean variable for each rule indicating its status, and flipping it to false when it becomes redundant. This version is based on procedure KBS_2 from Section 2.6[Sims1994].","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"Below is a julia-flavoured pseudocode describing the completion procedure.","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"function knuthbendix2(rws::RewritingSystem{W}, ...) where W\n    stack = Vector{Tuple{W,W}}()\n    rws = reduce(rws) # this is assumed by forceconfluence!\n\n    # ... initialize some temporary structures here\n    for ri in rules(rws)\n        for rj in rules(rws)\n            isactive(ri) || break\n            forceconfluence!(rws, stack, ri, rj, ...)\n\n            ri === rj && break\n            isactive(ri) || break\n            isactive(rj) || continue\n            forceconfluence!(rws, stack, rj, ri, ...)\n        end\n    end\n    remove_inactive!(rws) # all active rules form a reduced confluent rws\n    return rws\nend","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"CurrentModule = KnuthBendix","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"Not much has changed on the surface, but there are more substantial changes under the hood. In particular forceconfluence! has become simply","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"function forceconfluence!(rws::RewritingSystem, stack, ri, rj, ...)\n    find_critical_pairs!(stack, rws, ri, rj, ...)\n    deriverules!(rws, stack, ...)\n    return rws\nend","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"I.e. we first push all failures to local confluence derived from ri and rj onto stack ((find_critical_pairs!)), then empty the stack (deriverule!). To do this the top pair lhs → rhs is picked from the stack, we mark all the rules in rws that could be reduced with lhs as inactive and push them onto the stack. Only afterwards we push lhs → rhs to rws and we repeat until the stack is empty. More formally, in julia-flavoured pseudocode,","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"while !isempty(stack)\n    (a, b) = pop!(stack)\n    A, B = rewrite(a, rws), rewrite(b, rws)\n    if A ≠ B\n        new_rule = Rule(A,B, ordering(rws))\n        for rule in rules(rws)\n            if isreducible(rule, new_rule)\n                deactivate!(rule)\n                push!(stack, rule)\n            end\n        end\n        push!(rws, new_rule)\n    end\nend","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"Note that in knuthbendix2 we can break (or continue) on the inactivity of rules as specified in the listing above. Moreover those checks should be repeated after every call to forceconfluence! as in the process the rule being currently processed could have been marked as inactive (i.e. possibly redundant).","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"knuthbendix2\nforceconfluence!(::RewritingSystem, stack, r₁, r₂, ::Workspace)\nfind_critical_pairs!(stack, rewritng, ::Rule, ::Rule, ::Workspace)\nderiverule!(::RewritingSystem, stack, ::Workspace)\nreduce!(::KBS2AlgPlain, ::RewritingSystem, work::Workspace)","category":"page"},{"location":"knuthbendix2/#KnuthBendix.knuthbendix2","page":"Using a stack","title":"KnuthBendix.knuthbendix2","text":"knuthbendix2(rws::RewritingSystem; max_rules::Integer=100)\n\nRun the Knuth-Bendix procedure that (if successful) yields the reduced, confluent rewriting system generated by rules of rws.\n\nThis implementation follows closely KBS_2 procedure as described in\n\nCh.C. Sims Computation with finitely presented groups [Section 2.6 The Knuth-Bendix procedure, p.76].\n\nwarning: Warning\nForced termination takes place after the number of active rules stored in the RewritingSystem reaches max_rules.\n\n\n\n\n\n","category":"function"},{"location":"knuthbendix2/#KnuthBendix.forceconfluence!-Tuple{RewritingSystem, Any, Any, Any, KnuthBendix.Workspace}","page":"Using a stack","title":"KnuthBendix.forceconfluence!","text":"forceconfluence!(rws::RewritingSystem, stack, r₁, r₂[, work = Workspace(rws)])\n\nExamine overlaps of left hand sides of rules r₁ and r₂ to find (potential) failures to local confluence. New rules are added to assure local confluence if necessary.\n\nThis version assumes the reducedness of rws so that failures to local confluence are of the form a·b·c with all a, b, c non trivial and lhs₁ = a·b and lhs₂ = b·c.\n\nThis version uses stack to maintain the reducedness of rws and work::Workspace to save allocations in the rewriting.\n\nSee procedure OVERLAP_2 in [Sims, p. 77].\n\n\n\n\n\n","category":"method"},{"location":"knuthbendix2/#KnuthBendix.find_critical_pairs!-Tuple{Any, Any, KnuthBendix.Rule, KnuthBendix.Rule, KnuthBendix.Workspace}","page":"Using a stack","title":"KnuthBendix.find_critical_pairs!","text":"find_critical_pairs!(stack, rws, r₁::Rule, r₂::Rule[, work=Workspace(rws))\n\nFind critical pairs derived from suffix-prefix overlaps of lhses of r₁ and r₂.\n\nSuch failures (i.e. failures to local confluence) arise as W = ABC where AB, BC are the left-hand-sides of rules r₁ and r₂, respectively. It is assumed that all A, B and C are nonempty.\n\n\n\n\n\n","category":"method"},{"location":"knuthbendix2/#KnuthBendix.deriverule!-Tuple{RewritingSystem, Any, KnuthBendix.Workspace}","page":"Using a stack","title":"KnuthBendix.deriverule!","text":"deriverule!(rws::RewritingSystem, stack[, work = Workspace(rws)])\n\nEmpty stack of (potentially) critical pairs by deriving and adding new rules to rws resolving the pairs, i.e. maintains local confluence of rws.\n\nThis function may deactivate rules in rws if they are deemed redundant (e.g. follow from the added new rules). See [Sims, p. 76].\n\n\n\n\n\n","category":"method"},{"location":"knuthbendix2/#KnuthBendix.reduce!-Tuple{KnuthBendix.KBS2AlgPlain, RewritingSystem, KnuthBendix.Workspace}","page":"Using a stack","title":"KnuthBendix.reduce!","text":"reduce!(::NaiveKBS2Alg, rws::RewritingSystem)\n\nBring rws to its reduced form using the stack-based algorithm.\n\nA stack of active rules from rws is extracted, rws emptied and then the stack is merged into rws using the deriverule!.\n\n\n\n\n\n","category":"method"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"tip: Performance\nWhile knuthbendix2 vastly outperforms the naive knuthbendix1 it is still rather slow. There are two performance problems here which we will address next:the poor performance of naive rewriting that is still used by knuthbendix2: the complexity of this rewriting depends on the overall size of the rewriting system.\nthe fact that find_critical_pairs! and deriverules! assume and maintain the reducedness of the rewriting system and we pay a hefty price for this.","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"To address both problems we will use the theory of Automata and regular languages.","category":"page"},{"location":"knuthbendix2/","page":"Using a stack","title":"Using a stack","text":"[Sims1994]: C.C. Sims Computation with finitely presented groups,          Cambridge University Press, 1994.","category":"page"},{"location":"rewriting/#On-rewriting","page":"On rewriting","title":"On rewriting","text":"","category":"section"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"CurrentModule = KnuthBendix","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"rewrite","category":"page"},{"location":"rewriting/#KnuthBendix.rewrite","page":"On rewriting","title":"KnuthBendix.rewrite","text":"rewrite(u::AbstractWord, rewriting)\n\nRewrites word u using the rewriting object. The object must implement rewrite!(v::AbstractWord, w::AbstractWord, rewriting).\n\nExample\n\njulia> alph = Alphabet([:a, :A, :b], [2,1,3])\nAlphabet of Symbol\n  1. a    (inverse of: A)\n  2. A    (inverse of: a)\n  3. b    (self-inverse)\n\njulia> a = Word([1]); A = Word([2]); b = Word([3]);\n\njulia> rule = KnuthBendix.Rule(a*b => a)\n1·3 ⇒ 1\n\njulia> KnuthBendix.rewrite(a*b^2*A*b^3, rule) == a*A*b^3\ntrue\n\njulia> KnuthBendix.rewrite(a*A*b^3, alph) == b\ntrue\n\n\n\n\n\n\n","category":"function"},{"location":"rewriting/#Internals","page":"On rewriting","title":"Internals","text":"","category":"section"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"Implementing rewriting procedure naively could easily lead to quadratic complexity due to unnecessary moves of parts of the rewritten word. We follow the the linear-complexity algorithm in which we use two stacks and rewrite function calls internally","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"function rewrite!(v::AbstractWord, w::AbstractWord, rewriting; kwargs...)\n    ...\n    return v\nend","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"The semantics are that v and w are two stacks and","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"v is initially empty (represents the trivial word), while\nw contains the content of u (the word to be rewritten with its first letter on its top).","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"In practice we use BufferWords (a special implementation of AbstractWord API) and all our implementations the process is as follows.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"we pop the first letter l = popfirst!(w) from w,\nwe push l to the end of v,\nwe try to determine a rewritng rule lhs → rhs with v = v'·lhs (i.e. lhs is equal to a suffix of v) and we set\nv ← v' i.e. we remove the suffix fom v, and\nw ← rhs·w i.e. rhs is prepended to w\nif no such rule exists we go back to 1.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"These four steps are repeated until w becomes empty.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"Here are some examples of the internal rewriting function already defined:","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"rewrite!(::AbstractWord, ::AbstractWord, ::Rule)\nrewrite!(::AbstractWord, ::AbstractWord, ::Alphabet)","category":"page"},{"location":"rewriting/#KnuthBendix.rewrite!-Tuple{KnuthBendix.Words.AbstractWord, KnuthBendix.Words.AbstractWord, KnuthBendix.Rule}","page":"On rewriting","title":"KnuthBendix.rewrite!","text":"rewrite!(v::AbstractWord, w::AbstractWord, rule::Rule)\n\nRewrite word w storing the result in v by using a single rewriting rule.\n\nExample\n\njulia> a = Word([1]); A = Word([2]); b = Word([3]);\n\njulia> rule = KnuthBendix.Rule(a*b => a)\n1·3 ⇒ 1\n\njulia> v = one(a); KnuthBendix.rewrite!(v, a*b^2*A*b^3, rule);\n\njulia> v == a*A*b^3\ntrue\n\n\n\n\n\n","category":"method"},{"location":"rewriting/#KnuthBendix.rewrite!-Tuple{KnuthBendix.Words.AbstractWord, KnuthBendix.Words.AbstractWord, Alphabet}","page":"On rewriting","title":"KnuthBendix.rewrite!","text":"rewrite!(v::AbstractWord, w::AbstractWord, A::Alphabet)\n\nRewrite word w storing the result in v by applying free reductions as defined by the inverses present in alphabet A.\n\nExample\n\njulia> alph = Alphabet([:a, :A, :b], [2,1,3])\nAlphabet of Symbol\n  1. a    (inverse of: A)\n  2. A    (inverse of: a)\n  3. b    (self-inverse)\n\njulia> a = Word([1]); A = Word([2]); b = Word([3]);\n\njulia> v = one(a); KnuthBendix.rewrite!(v, a*b^2*A*b^3, alph);\n\njulia> v == b\ntrue\n\n\n\n\n\n","category":"method"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"Let a rewriting system rws is given, and let lhsₖ → rhsₖ denote its k-th rule. Let ℒ = {lhsₖ}ₖ denote the language of left-hand-sides of rws and let N = Σₖ nₖ be the total length of ℒ.","category":"page"},{"location":"rewriting/#Naive-rewriting","page":"On rewriting","title":"Naive rewriting","text":"","category":"section"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"The naive version is to check for every rule lhs → rhs in rws if v contains lhs as a suffix. If so, the suffix is removed from v, rhs is prepended to w and we move to the (new) first letter of w. With m = length(u) the complexity of this rewriting is Ω(m · N), i.e. it is proportional to the size of the whole rewriting system making it a very inefficient rewriting strategy.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"rewrite!(::AbstractWord, ::AbstractWord, ::RewritingSystem)","category":"page"},{"location":"rewriting/#KnuthBendix.rewrite!-Tuple{KnuthBendix.Words.AbstractWord, KnuthBendix.Words.AbstractWord, RewritingSystem}","page":"On rewriting","title":"KnuthBendix.rewrite!","text":"rewrite!(v::AbstractWord, w::AbstractWord, rws::RewritingSystem)\n\nRewrite word w storing the result in v using rewriting rules of rws.\n\nSee procedure REWRITE_FROM_LEFT from Section 2.4[Sims1994], p. 66.\n\n[Sims1994]: C.C. Sims Computation with finitely presented groups,          Cambridge University Press, 1994.\n\n\n\n\n\n","category":"method"},{"location":"rewriting/#Index-automaton","page":"On rewriting","title":"Index automaton","text":"","category":"section"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"Rewriting with an index automaton idxA traces (follows) the path in the automaton determined by w (since the automaton is deterministic there is only one such path). Whenever a terminal (i.e. accepting) state is encountered its corresponding rule lhs → rhs is retrived, the appropriate suffix of v (equal to lhs) is removed, and rhs is prepended to w. Tracing continues from the newly prepended letter.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"To continue tracing w through the automaton we need to backtrack on our path in the automaton and for this rewrite maintains a vector of visited states of idxA (the history of visited states of idxA). Whenever a suffix is removed from v, the path is rewinded (i.e. shortened) to the appropriate length and the next letter of w is traced from the last state on the path. This maintains the property that signature of the path is equal to v at all times.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"Once index automaton is build the complexity of this rewriting is Ω(m) which is the optimal rewriting strategy. In practice the complexity of building and maintaining idxA synchronized with ℒ overwhelms gains made in rewriting (to construct idxA one need to reduce rws first which is O(N²) (??)).","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"rewrite!(::AbstractWord, ::AbstractWord, ::Automata.IndexAutomaton; history)","category":"page"},{"location":"rewriting/#KnuthBendix.rewrite!-Tuple{KnuthBendix.Words.AbstractWord, KnuthBendix.Words.AbstractWord, KnuthBendix.Automata.IndexAutomaton}","page":"On rewriting","title":"KnuthBendix.rewrite!","text":"rewrite!(v::AbstractWord, w::AbstractWord, idxA::Automata.IndexAutomaton;\n    [history])\n\nRewrite word w storing the result in v using index automaton idx.\n\nSee procedure INDEX_REWRITE from Section 3.5[Sims1994], p. 113.\n\n[Sims1994]: C.C. Sims Computation with finitely presented groups,          Cambridge University Press, 1994.\n\n\n\n\n\n","category":"method"},{"location":"rewriting/#Non-deterministic-prefix-automaton","page":"On rewriting","title":"Non-deterministic prefix automaton","text":"","category":"section"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"Rewriting with a non-deterministic prefix automaton pfxA traces the whole set of paths in pfxA which are determined by w. Since pfxA contains an ε-labeled loop at its (unique) initial state, tracing w through pfxA amounts to tracing a set of paths where each begins at every letter of w. Whenever a terminal (i.e. accepting) state is encountered on any of the paths, the corresponding rule lhs →  rhs is retrived, the appropriate suffix of v (equal to lhs) is removed, and rhs is prepended to w.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"As above, to continue tracing the set of paths we need to backtrack each path and for this rewrite maintains the histories of visited states of pfxA for each path. Whenever a suffix is removed from v each path must be rewinded by an appropriate length.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"This rewriting can be also understood differently: given the non-deterministic automaton pfxA one could determinize it through power-set construction and then trace deterministicaly in the automaton whose states are subsets of states of pfxA. Here we do it without realizing the power-set explicitly and we are tracing through procedute described in Sims as accessible subset construction.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"In practice the history consists of the subsets of states (of pfxA) which are stored in a contiguous array and an additional vector of indices marking the separation indices is added. A new path is started whenever a new letter is pushed onto v by simply adding the the initial state of pfxA to the current subset. The rewinding of the history then can be done simultanuously for all paths (without much bookkeeping) by shortening the vector of separators and resizing contiguous array of states accordingly.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"Once prefix automaton is build the complexity of this rewriting is Ω(m²). This rewriting strikes a balance between the complexity of rewriting and the synchronization of pfxA and ℒ, as the insertion and the removal of a word w to pfxA has complexity O(m).","category":"page"},{"location":"rewriting/#Even-more-internals-of-rewriting","page":"On rewriting","title":"Even more internals of rewriting","text":"","category":"section"},{"location":"rewriting/#On-BufferWords","page":"On rewriting","title":"On BufferWords","text":"","category":"section"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"Rewriting is a crucial part of the Knuth-Bendix completion. In particular we do care plenty not only about the theoretical complexity, but also the practical speed of rewriting. You may be surprised then that a simple rewrite allocates 6 times:","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"CurrentModule = KnuthBendix\nDocTestFilters = r\"[0-9\\.]+ seconds \\(.*\\)\"\nDocTestSetup  = quote\n    using KnuthBendix\nend","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"julia> alph = Alphabet([:a, :A, :b], [2,1,3])\nAlphabet of Symbol\n  1. a    (inverse of: A)\n  2. A    (inverse of: a)\n  3. b    (self-inverse)\n\njulia> a = Word([1]); A = Word([2]); b = Word([3]);\n\njulia> w = a*A*b^3;\n\njulia> @time KnuthBendix.rewrite(w, alph)\n  0.000015 seconds (6 allocations: 272 bytes)\nWord{UInt16}: 3\n","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"DocTestFilters = nothing","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"This is because the system is tuned towards re-using the storage in the process of the completion. In particular two Words.BufferWord and the final returned word (of the same type as w) are allocated in the process:","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"function rewrite(\n    w::W,\n    rewriting,\n    vbuff = Words.BufferWord{T}(0, length(u)),\n    wbuff = Words.BufferWord{T}(0, length(u));\n    kwargs...,\n) where {T,W<:AbstractWord{T}}\n    # first copy the content of w into wbuff then\n    rewrite!(vbuff, wbuff, rewriting; kwargs...)\n    # finally take ownership of the content of vbuff\n    return W(vbuff)\nend","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"Words.BufferWord is an implementation of AbstractWord tuned for the purpose of this form of rewriting (with O(1) complexity for popfirst!, push! and prepend!). In the Knuth-Bendix completion these BufferWords are allocated only once per run and re-used as much as possible, so that destructive rewriting is as free from allocations and memory copy as possible.","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"In particular rewriting with BufferPair saves all of those allocations at the cost of owning the result:","category":"page"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"rewrite!(::KnuthBendix.BufferPair, u::AbstractWord, rewriting)","category":"page"},{"location":"rewriting/#KnuthBendix.rewrite!-Tuple{KnuthBendix.BufferPair, KnuthBendix.Words.AbstractWord, Any}","page":"On rewriting","title":"KnuthBendix.rewrite!","text":"function rewrite!(bp::BufferPair, u::AbstractWord, rewriting)\n\nRewrites a word from left using buffer words from BufferPair and rewriting object.\n\nwarning: Warning\nThis implementation returns an instance of Words.BufferWord aliased with the intenrals of BufferPair. You need to copy the return value if you want to take the ownership.\n\n\n\n\n\n","category":"method"},{"location":"rewriting/","page":"On rewriting","title":"On rewriting","text":"BufferPair is just a convinience struct that bundles everything for allocation-free rewriting. While it is used extensively during Knuth-Bendix completion you should never see it outside of it!","category":"page"},{"location":"KB_implementations/#Implementations-of-Knuth-Bendix-completion","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"","category":"section"},{"location":"KB_implementations/#In-KnuthBendix.jl","page":"Implementations of Knuth-Bendix completion","title":"In KnuthBendix.jl","text":"","category":"section"},{"location":"KB_implementations/","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"There are currently four implementations available:","category":"page"},{"location":"KB_implementations/","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"KBS1AlgPlain which follows the naive version,\nKBS2AlgPlain which uses stack and rule deactivation to maintain reducedness.\nKBS2AlgRuleDel - a modification of KBSAlgPlain which frequently deletes the rules which are deemed redundant.\nKBS2AlgIndexAut - a modification of KBSAlgPlain which uses IndexAutomaton to obtain optimal complexity of rewriting.","category":"page"},{"location":"KB_implementations/","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"In general all of those methods dispatch through common interface:","category":"page"},{"location":"KB_implementations/","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"CurrentModule = KnuthBendix","category":"page"},{"location":"KB_implementations/","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"knuthbendix","category":"page"},{"location":"KB_implementations/#KnuthBendix.knuthbendix","page":"Implementations of Knuth-Bendix completion","title":"KnuthBendix.knuthbendix","text":"knuthbendix(rws::RewritingSystem[, settings=Settings()])\nknuthbendix(method::CompletionAlgorithm, rws::RewritingSystem[, settings:Settings()])\n\nPerform Knuth-Bendix completion on rewriting system rws using algorithm defined by method.\n\nA reduced rewriting system is returned.\n\nBy default method = KBS2AlgIndexAut() is used.\n\n\n\n\n\n","category":"function"},{"location":"KB_implementations/#Knuth-Bendix-on-Monoids-and-Automatic-Groups-(kbmag)","page":"Implementations of Knuth-Bendix completion","title":"Knuth-Bendix on Monoids and Automatic Groups (kbmag)","text":"","category":"section"},{"location":"KB_implementations/","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"The baseline C-implementation of the Knuth-Bendix completion (and much more!) used by the GAP System. See kbmag source code and the documentation of the GAP interface.","category":"page"},{"location":"KB_implementations/","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"Much wider functionality (automatic structures, etc.) and way more tuning options. In maintainance mode since ca. 1996.","category":"page"},{"location":"KB_implementations/#Monoid-Automata-Factory-(maf)","page":"Implementations of Knuth-Bendix completion","title":"Monoid Automata Factory (maf)","text":"","category":"section"},{"location":"KB_implementations/","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"Somehow more advanced and modern C++-implementation of similar functionality to kbmag (it even has kbmag interface!). According to their docs","category":"page"},{"location":"KB_implementations/","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"MAF succeeds on many examples where KBMAG either fails, or requires a very careful selection of options to succeed. In particular, MAF will usually work better with recursive orderings.","category":"page"},{"location":"KB_implementations/","page":"Implementations of Knuth-Bendix completion","title":"Implementations of Knuth-Bendix completion","text":"See package documentation and its source code. Not actively developed since 2011.","category":"page"},{"location":"orders/#Orders","page":"Orders","title":"Orders","text":"","category":"section"},{"location":"orders/","page":"Orders","title":"Orders","text":"KnuthBendix.RewritingOrdering\n\nalphabet","category":"page"},{"location":"orders/#KnuthBendix.RewritingOrdering","page":"Orders","title":"KnuthBendix.RewritingOrdering","text":"RewritingOrdering\n\nAbstract type representing translation bi-invariant well-orderings on free monoids over an alphabet. Translation (bi-)invariance means that whenever u < v, then aub < avb for arbitrary words a and b. In particular ε (the monoid identity) is the smallest word for any RewritingOrdering.\n\nThe subtypes of RewritingOrdering must implement:\n\nalphabet which returns the underlying alphabet, over which a particular order is defined;\nBase.Order.lt(o::RewritingOrdering, a::AbstractWord, b::AbstractWord) to test whether a is less than b according to the ordering o.\n\n\n\n\n\n","category":"type"},{"location":"orders/#KnuthBendix.alphabet","page":"Orders","title":"KnuthBendix.alphabet","text":"alphabet(ord::RewritingOrdering)\n\nReturn the alphabet of the free monoid on which ord is defined.\n\n\n\n\n\nalphabet(rws::RewritingSystem)\n\nReturn the underlying Alphabet of the rewriting system.\n\n\n\n\n\n","category":"function"},{"location":"orders/#Lexicographical-orderings","page":"Orders","title":"Lexicographical orderings","text":"","category":"section"},{"location":"orders/","page":"Orders","title":"Orders","text":"LenLex\nWeightedLex","category":"page"},{"location":"orders/#KnuthBendix.LenLex","page":"Orders","title":"KnuthBendix.LenLex","text":"LenLex{T} <: LexOrdering\nLenLex(A::Alphabet[; order=collect(A)])\n\nCompare words first by their length, then break ties by (left-)lexicographic order.\n\nExample\n\njulia> Al = Alphabet([:a, :A, :b, :B]);\n\njulia> ll1 = LenLex(Al)\nLenLex: a < A < b < B\n\njulia> ll2 = LenLex(Al, order=[:a, :b, :A, :B])\nLenLex: a < b < A < B\n\njulia> a, A, b, B = [Word([i]) for i in 1:length(Al)];\n\njulia> lt(ll1, a*A, a*b)\ntrue\n\njulia> lt(ll2, a*A, a*b)\nfalse\n\n\n\n\n\n","category":"type"},{"location":"orders/#KnuthBendix.WeightedLex","page":"Orders","title":"KnuthBendix.WeightedLex","text":"WeightedLex{T,S} <: LexOrdering\nWeightedLex(A::Alphabet; weights[, order=collect(A)])\n\nCompare words first by their weight, then break ties by (left-)lexicographic order.\n\nThe weights vector assigns weights to each letter as they appear in the alphabet and the weight of a word is the sum of weights of all of its letters.\n\nWith all weights equal to 1 WeightedLex becomes LenLex.\n\nExample\n\njulia> al = Alphabet([:a, :A, :b, :B]);\n\njulia> a, A, b, B = (Word([i]) for i in 1:length(al));\n\njulia> wtlex = WeightedLex(al, weights=[1, 2, 3, 4], order=[:a, :b, :B, :A])\nWeightedLex: a(1) < b(3) < B(4) < A(2)\n\njulia> lt(wtlex, b * B, B * a * a * a)\ntrue\n\njulia> lt(wtlex, A*B, B*A)\nfalse\n\n\n\n\n\n","category":"type"},{"location":"orders/#Wreath-orderings","page":"Orders","title":"Wreath orderings","text":"","category":"section"},{"location":"orders/","page":"Orders","title":"Orders","text":"WreathOrder\nRecursive","category":"page"},{"location":"orders/#KnuthBendix.WreathOrder","page":"Orders","title":"KnuthBendix.WreathOrder","text":"WreathOrder{T,S} <: RewritingOrdering\nWreathOrder(A::Alphabet; levels[, order=collect(A)])\n\nCompare words first by their levels, then break ties by recursion on prefixes.\n\nThe levels vector assigns levels to each letter as they appear in the alphabet and the level of a word is the maximum of levels of all its letters.\n\nThe order compare words first by their levels, then break ties by LenLex order of pure max-level words. Further ties are resolved by recursing on lower level prefixes.\n\nDefinition\n\nLet U = U₀·a₁·U₁·…·aᵣ·Uᵣ be a decomposition of U such that\n\nall aᵢs are at the same (maximal) level and\neach Uᵢ is at level strictly smaller.\n\nLet V = V₀·b₁·V₁·…·bₛ·Vₛ be a similar decomposition. Then U <≀ V if either\n\na₁·…·aᵣ < b₁·…·bₛ according to LenLex order, or\na₁·…·aᵣ = b₁·…·bₛ and U₀ <≀ V₀, or Uᵢ = Vᵢ for 0≤i<k but Uₖ <≀ Vₖ.\n\nFor more references see\n\nC. Sims Computation with finitely presented groups, p. 46-47\nD. Holt, B. Eick and E. O’Brien Handbook of Computational Group Theory, Section 12.4 Rewriting systems for polycyclic groups, p. 426-427\nS. Rees Automatic groups associated with word orders other than shortlex Section 5.3 Wreath product orders.\n\nExample\n\njulia> X = Alphabet([:a, :b]);\n\njulia> a, b = Word([1]), Word([2]);\n\njulia> wro = WreathOrder(X, levels = [1, 2])\nWreathOrder: a(1) < b(2)\n\njulia> lt(wro, a^100, a * b * a^2) # by level only\ntrue\n\njulia> lt(wro, b^2*a, a^2 * b * a) # by max-level word\nfalse\n\njulia> lt(wro, a * b * a^2, a^2 * b * a) # by the lower level prefix\ntrue\n\n\n\n\n\n","category":"type"},{"location":"orders/#KnuthBendix.Recursive","page":"Orders","title":"KnuthBendix.Recursive","text":"Recursive{Side,T} <: RewritingOrdering\nRecursive{Side}(A::Alphabet; order=collect(A))\n\nA special case of WreathOrder where each letter is given a unique level.\n\nSince levels are unique they just linearly order letters in the alphabet A. The order generally promotes smaller generators, and larger ones will occur in minimal words relatively early. For example if a < b then a·b > b·aⁿ.\n\nDefinition\n\nGiven a partial order (A, <) on an alphabet A, for p, q ∈ A* we say that p < q w.r.t. left-recursive ordering if\n\np == ε ≠ q, or\np = p′·a, q = q′·b for some a, b ∈ A and\na == b and p′ < q′, or\na < b and p < q′, or\na > b and p′ < q\n\nFor the right-recursive ordering one needs to change the decompositions in point 2. to\n\np = a·p′, q = b·q′ for some a, b ∈ A …\n\nFor more details consult\n\nM. Jentzen Confluent String Rewriting, Definition 1.2.14 p.24.\n\nThe ordering is sometimes also known as recursive path ordering and is useful e.g. for polycyclic groups.\n\nExample\n\njulia> X = Alphabet([:a, :A, :b],[2,1,0]);\n\njulia> a, A, b = [Word([i]) for i in 1:length(X)];\n\njulia> rec = Recursive(X, order=[:a, :A, :b])\nKnuthBendix.Left-Recursive: a < A < b\n\njulia> lt(rec, b*a^10, a*b)\ntrue\n\njulia> lt(rec, b*a^10, b)\nfalse\n\njulia> lt(rec, a*A, b*a^10)\ntrue\n\njulia> rt_rec = Recursive{KnuthBendix.Right}(X, order=[:a, :A, :b])\nKnuthBendix.Right-Recursive: a < A < b\n\n\n\n\n\n","category":"type"},{"location":"#Knuth-Bendix-completion-focused-on-groups-and-monoids","page":"Home","title":"Knuth-Bendix completion focused on groups and monoids","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package implements the Knuth-Bendix completion for groups and monoids given by a finite presentation. It's neither serious, nor performant implementation compared to other implementations out-there, namely kbmag by Derek Holt, or maf by Allun Williams. It was written more for the purpose of learning the fascinating topic of computation with finitely presented groups. Nonetheless the implementation is usable, clean and hopefully fun to experiment with.","category":"page"}]
}
